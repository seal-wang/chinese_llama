{
    "model_name_or_path": "./llama_zh/model/",
    "tokenizer_name": "./llama_zh/tokenizer/",
    "train_file": "./data/",
    "per_device_train_batch_size": 4,
    "gradient_accumulation_steps": 1,
    "do_train": true,
    "output_dir": "./output/",
    "cache_dir": "./cache_dir/",
    "logging_strategy": "steps",
    "logging_steps": 500,
    "logging_dir": "./log_dir/",
    "save_strategy": "epoch",
    "save_steps": 1,
    "save_total_limit": 5,
    "seed":100,
    "data_seed":100,
    "trust_remote_code": true,
    "block_size": 512,
    "overwrite_output_dir": true,
    "num_train_epochs": 4,
    "gradient_checkpointing": true,
    "fp16": true,
    "torch_dtype": "float16",
    "max_grad_norm": 0,
    "preprocessing_num_workers": 1,
    "no_cuda": false,
    "deepspeed": "ds_zero2_no_offload.json",
    "from_scratch": true,
    "lora_rank": 16,
    "lora_alpha": 32,
    "lora_dropout": 0.05,
    "trainable": "q_proj,v_proj,k_proj,o_proj,gate_proj,down_proj,up_proj"	
}
